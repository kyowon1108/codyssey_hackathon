# ì‹œìŠ¤í…œ ê°œì„  ê³„íšì„œ

## âœ… ì™„ë£Œëœ ì‘ì—…

### 1. ë°ì´í„°ë² ì´ìŠ¤ ì¸í”„ë¼ êµ¬ì¶•
- **íŒŒì¼**: `database.py`
- **ë‚´ìš©**:
  - SQLAlchemy ê¸°ë°˜ ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ìƒì„±
  - Job ëª¨ë¸: ì‘ì—… ì •ë³´, ìƒíƒœ, í†µê³„, ì—ëŸ¬ ì¶”ì 
  - ErrorLog ëª¨ë¸: ìƒì„¸í•œ ì—ëŸ¬ ë¡œê¹…
  - CRUD í•¨ìˆ˜: create_job, get_job_by_id, update_job_status, etc.

### 2. Requirements ì—…ë°ì´íŠ¸
- SQLAlchemy ì¶”ê°€

## ğŸš§ ì§„í–‰ ì¤‘ì¸ ì‘ì—…

### 3. main.py ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
í˜„ì¬ `main.py`ëŠ” ë©”ëª¨ë¦¬ ê¸°ë°˜ `jobs`, `pub_to_job` ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.
ì´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì „í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

**í•„ìš”í•œ ìˆ˜ì •ì‚¬í•­**:

#### A. ì „ì—­ ë³€ìˆ˜ ì œê±°
```python
# ì œê±°í•  ì½”ë“œ:
jobs = {}  # job_id -> ì •ë³´(dict: status, pub_key, etc.)
pub_to_job = {}  # pub_key -> job_id ë§¤í•‘

# ì¶”ê°€í•  ì½”ë“œ:
# Database initialization
init_db()  # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
```

#### B. recover_existing_jobs() í•¨ìˆ˜ ìˆ˜ì •
```python
# ê¸°ì¡´: ë©”ëª¨ë¦¬ì— ë³µêµ¬
# ìˆ˜ì •: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìë™ ë³µêµ¬ (DBì— ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆìŒ)
def recover_existing_jobs():
    """
    ì„œë²„ ì¬ì‹œì‘ ì‹œ DBì—ì„œ RUNNING ìƒíƒœì¸ ì‘ì—…ë“¤ì„ PENDINGìœ¼ë¡œ ë³€ê²½
    """
    db = next(get_db())
    running_jobs = get_running_jobs(db)
    for job in running_jobs:
        logger.warning(f"Found interrupted job: {job.job_id}, resetting to PENDING")
        update_job_status(db, job.job_id, "PENDING")
    db.close()
```

#### C. create_reconstruction_job() API ìˆ˜ì •
```python
@app.post("/recon/jobs")
async def create_reconstruction_job(
    files: list[UploadFile] = File(...),
    original_resolution: bool = False,
    db: Session = Depends(get_db)  # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì£¼ì…
):
    # 1. ì´ë¯¸ì§€ ê²€ì¦ ì¶”ê°€
    for file in files:
        validate_image_file(file)  # ìƒˆë¡œìš´ ê²€ì¦ í•¨ìˆ˜

    # 2. Job ID ìƒì„±
    job_id = uuid.uuid4().hex[:8]
    pub_key = ''.join(random.choice("0123456789") for _ in range(10))

    # 3. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    try:
        job = create_job(
            db,
            job_id=job_id,
            pub_key=pub_key,
            image_count=len(files),
            original_resolution=original_resolution,
            iterations=10000
        )
    except Exception as e:
        logger.error(f"Failed to create job in database: {e}")
        raise HTTPException(500, "Failed to create job")

    # 4. ì´ë¯¸ì§€ ì €ì¥ ë° ì‘ì—… ì‹œì‘
    # ... (ê¸°ì¡´ ì½”ë“œ)

    # 5. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘
    asyncio.create_task(process_job(job_id))

    return {
        "job_id": job_id,
        "pub_key": pub_key,
        "original_resolution": original_resolution
    }
```

#### D. process_job() í•¨ìˆ˜ ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
```python
async def process_job(job_id: str):
    """
    ì£¼ì–´ì§„ job_idì— ëŒ€í•´ COLMAP ë° Gaussian Splatting íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    db = next(get_db())
    job = get_job_by_id(db, job_id)

    if not job:
        logger.error(f"Job {job_id} not found in database")
        return

    async with sem:
        job_dir = Path(BASE_DIR / job_id)
        log_path = job_dir / "run.log"

        try:
            # ìƒíƒœ ì—…ë°ì´íŠ¸: RUNNING
            update_job_status(db, job_id, "RUNNING")

            with open(log_path, 'a', encoding='utf-8', buffering=1) as log_file:
                log_file.write(f"=== Job {job_id} started ===\n")

                # ========== COLMAP Feature Extraction ==========
                try:
                    log_file.write(">> [1/6] Feature extraction...\n")
                    await run_command([...], log_file)
                except Exception as e:
                    error_msg = f"Feature extraction failed: {str(e)}"
                    log_error(db, job_id, "colmap_feature", type(e).__name__, error_msg, traceback.format_exc())
                    raise

                # ========== COLMAP Feature Matching ==========
                try:
                    log_file.write(">> [2/6] Feature matching...\n")
                    await run_command([...], log_file)
                except Exception as e:
                    error_msg = f"Feature matching failed: {str(e)}"
                    log_error(db, job_id, "colmap_matching", type(e).__name__, error_msg, traceback.format_exc())
                    raise

                # ... ê° ë‹¨ê³„ë§ˆë‹¤ try-except ì¶”ê°€

                # ========== Gaussian Splatting Training ==========
                try:
                    log_file.write(">> [5/6] Gaussian Splatting training...\n")
                    await run_command(gs_train_cmd, log_file, env=env, monitor_gpu=True)

                    # í†µê³„ ì—…ë°ì´íŠ¸
                    ply_file = iter_dir / "point_cloud_filtered.ply"
                    if ply_file.exists():
                        gaussian_count = count_gaussians(ply_file)
                        file_size_mb = ply_file.stat().st_size / (1024 * 1024)

                        update_job_results(
                            db,
                            job_id,
                            gaussian_count=gaussian_count,
                            file_size_mb=file_size_mb
                        )

                except Exception as e:
                    error_msg = f"Gaussian Splatting failed: {str(e)}"
                    log_error(db, job_id, "gaussian_splatting", type(e).__name__, error_msg, traceback.format_exc())
                    raise

                # ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
                update_job_status(db, job_id, "DONE")
                log_file.write(f"=== Job {job_id} completed successfully ===\n")

        except Exception as e:
            # ì „ì²´ ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬
            error_msg = f"Job failed: {str(e)}"
            logger.error(error_msg)
            log_error(db, job_id, "general", type(e).__name__, error_msg, traceback.format_exc())
            update_job_status(db, job_id, "FAILED", error_message=str(e))

        finally:
            db.close()
```

#### E. get_job_status() API ìˆ˜ì •
```python
@app.get("/recon/jobs/{job_id}/status")
async def get_job_status(job_id: str, db: Session = Depends(get_db)):
    job = get_job_by_id(db, job_id)

    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # ë¡œê·¸ íŒŒì¼ ì½ê¸°
    log_path = Path(BASE_DIR / job_id / "run.log")
    log_tail = []
    if log_path.exists():
        try:
            with open(log_path, 'r') as f:
                lines = f.readlines()
                log_tail = lines[-10:] if lines else []
        except Exception as e:
            log_tail = [f"(log read error: {e})"]

    response = {
        "job_id": job.job_id,
        "status": job.status,
        "log_tail": log_tail,
        "created_at": job.created_at.isoformat() if job.created_at else None,
        "processing_time_seconds": job.processing_time_seconds,
        "image_count": job.image_count,
        "gaussian_count": job.gaussian_count,
        "file_size_mb": job.file_size_mb
    }

    if job.status == "DONE":
        response["viewer_url"] = f"/v/{job.pub_key}"
    elif job.status == "FAILED":
        response["error"] = job.error_message
        response["error_stage"] = job.error_stage

    return JSONResponse(content=response)
```

#### F. view_result_page() API ìˆ˜ì •
```python
@app.get("/v/{pub_key}", response_class=HTMLResponse)
async def view_result_page(pub_key: str, request: Request, db: Session = Depends(get_db)):
    job = get_job_by_pub_key(db, pub_key)

    if not job:
        raise HTTPException(status_code=404, detail="Invalid viewer key")

    if job.status != "DONE":
        return HTMLResponse(content="<html><body><h3>Result is not ready yet. Please check again later.</h3></body></html>")

    # Load viewer
    viewer_path = Path(__file__).parent / "viewer_template.html"
    with open(viewer_path, 'r') as f:
        html_content = f.read()

    splat_url = f"/recon/pub/{pub_key}/scene.splat"
    html_content = html_content.replace('SPLAT_URL_PLACEHOLDER', splat_url)
    return HTMLResponse(content=html_content, status_code=200)
```

#### G. ì´ë¯¸ì§€ ê²€ì¦ í•¨ìˆ˜ ì¶”ê°€
```python
def validate_image_file(file: UploadFile):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ì´ ìœ íš¨í•œ ì´ë¯¸ì§€ì¸ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    from PIL import Image
    import io

    # íŒŒì¼ í™•ì¥ì ì²´í¬
    allowed_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}
    file_ext = Path(file.filename).suffix

    if file_ext not in allowed_extensions:
        raise HTTPException(400, f"Unsupported file type: {file_ext}. Allowed: {allowed_extensions}")

    # íŒŒì¼ ë‚´ìš© ê²€ì¦
    try:
        content = file.file.read()
        img = Image.open(io.BytesIO(content))
        img.verify()  # ì´ë¯¸ì§€ íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦

        # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
        file.file.seek(0)

        # ìµœì†Œ í¬ê¸° ì²´í¬
        if img.width < 100 or img.height < 100:
            raise HTTPException(400, f"Image too small: {img.width}x{img.height}. Minimum: 100x100")

        logger.info(f"Validated image: {file.filename} ({img.width}x{img.height})")

    except Exception as e:
        raise HTTPException(400, f"Invalid image file: {file.filename}. Error: {str(e)}")
```

#### H. Gaussian ì¹´ìš´íŒ… í•¨ìˆ˜ ì¶”ê°€
```python
def count_gaussians(ply_file: Path) -> int:
    """
    PLY íŒŒì¼ì—ì„œ Gaussian ê°œìˆ˜ë¥¼ ì¹´ìš´íŠ¸í•©ë‹ˆë‹¤.
    """
    try:
        from plyfile import PlyData
        plydata = PlyData.read(str(ply_file))
        return len(plydata['vertex'])
    except Exception as e:
        logger.error(f"Failed to count gaussians: {e}")
        return 0
```

## ğŸ“‹ ë‚¨ì€ ì‘ì—…

### ìš°ì„ ìˆœìœ„ 1: í•µì‹¬ ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] main.pyì— ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì™„ë£Œ
- [ ] ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ DB ê¸°ë°˜ìœ¼ë¡œ ì „í™˜
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™” ì™„ë£Œ

### ìš°ì„ ìˆœìœ„ 2: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
- [ ] ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
- [ ] ì„œë²„ ì¬ì‹œì‘ í›„ ì‘ì—… ë³µêµ¬ í…ŒìŠ¤íŠ¸
- [ ] ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ í™•ì¸

### ìš°ì„ ìˆœìœ„ 3: ì¶”ê°€ ê¸°ëŠ¥
- [ ] ì‘ì—… ì·¨ì†Œ API
- [ ] ì‘ì—… ì‚­ì œ API
- [ ] ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ (ëª¨ë“  ì‘ì—… ì¡°íšŒ)

## ğŸ”§ ì ìš© ë°©ë²•

### ë°©ë²• 1: ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ (ê¶Œì¥)
1. í˜„ì¬ main.pyë¥¼ main_old.pyë¡œ ë°±ì—…
2. ìƒˆë¡œìš´ main.py ì‘ì„± (DB ê¸°ë°˜)
3. í…ŒìŠ¤íŠ¸
4. ë¬¸ì œ ì—†ìœ¼ë©´ main_old.py ì‚­ì œ

### ë°©ë²• 2: í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹
1. DBë¥¼ ì¶”ê°€í•˜ë˜, ë©”ëª¨ë¦¬ ìºì‹œë„ ìœ ì§€
2. ì„±ëŠ¥ê³¼ ì•ˆì •ì„± í™•ë³´
3. ë‚˜ì¤‘ì— ë©”ëª¨ë¦¬ ìºì‹œ ì œê±°

## ğŸ“Š ì˜ˆìƒ íš¨ê³¼

### Before (ë©”ëª¨ë¦¬ ê¸°ë°˜)
- âŒ ì„œë²„ ì¬ì‹œì‘ ì‹œ ì‘ì—… ì •ë³´ ì†ì‹¤
- âŒ ì—ëŸ¬ ì¶”ì  ì–´ë ¤ì›€
- âŒ í†µê³„ ë°ì´í„° ì—†ìŒ
- âŒ ì‘ì—… íˆìŠ¤í† ë¦¬ ì—†ìŒ

### After (DB ê¸°ë°˜)
- âœ… ì˜êµ¬ ì €ì¥, ì„œë²„ ì¬ì‹œì‘ ì•ˆì „
- âœ… ìƒì„¸í•œ ì—ëŸ¬ ë¡œê¹… ë° ì¶”ì 
- âœ… í†µê³„ ë° ë¶„ì„ ê°€ëŠ¥
- âœ… ì‘ì—… íˆìŠ¤í† ë¦¬ ë° ê²€ìƒ‰ ê°€ëŠ¥
- âœ… ìƒìš© ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. **SQLAlchemy ì„¤ì¹˜**:
   ```bash
   pip install sqlalchemy
   ```

2. **ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”**:
   ```python
   from database import init_db
   init_db()
   ```

3. **main.py ìˆ˜ì • ì ìš©**

4. **í…ŒìŠ¤íŠ¸**

5. **Git commit**

---

**ì‘ì„±ì¼**: 2025-10-12
**ì‘ì„±ì**: Claude Code
